{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:32:58.482098Z",
     "start_time": "2019-10-16T21:32:58.041858Z"
    }
   },
   "outputs": [],
   "source": [
    "import music\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.oauth2 as oauth2\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "path = os.getcwd() + '/data/'\n",
    "raw_path = path + 'raw/'\n",
    "billboard_path = path + 'external/billboard_weeks'\n",
    "fuzzy_path = path + 'interim/'\n",
    "model_path = path + 'model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:32:34.682698Z",
     "start_time": "2019-10-16T21:32:34.647215Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_playlist_tracks_full(spotify_connection, user, playlist_id = None, fields = None, market = None):\n",
    "    \"\"\" \n",
    "    args:\n",
    "        user: User ID of playlist owner\n",
    "        playlist_id: ID of the Spotify playlist\n",
    "        fields: Can select specific fields to return. Refer to Spotify documentation for further details\n",
    "        market: Country code\n",
    "        \n",
    "    \"\"\"\n",
    "    # first run through also retrieves total no of songs in library\n",
    "    response = spotify_connection.user_playlist_tracks(user, playlist_id, fields=fields, limit=100, market=market)\n",
    "    results = response[\"items\"]\n",
    "\n",
    "    # subsequently runs until it hits the user-defined limit or has read all songs in the library\n",
    "    while len(results) < response[\"total\"]:\n",
    "        response = spotify_connection.user_playlist_tracks(\n",
    "            user, playlist_id, fields = fields, limit = 100, offset = len(results), market = market)\n",
    "        results.extend(response[\"items\"])\n",
    "    return results\n",
    "\n",
    "def scrape_spotify(user, playlist):\n",
    "    \n",
    "    '''\n",
    "    Function to create a dataframe of audio features, given the user name and playlist id\n",
    "    Args:\n",
    "        spotify_connection: spotipy.Spotify(auth = token) object\n",
    "        user: Name of user that playlist is extracted from. Enter in string format\n",
    "        playlist_id: id of Spotify playlist. Under share, select copy Spotify uri\n",
    "    \n",
    "    Returns: DataFrame object\n",
    "    '''\n",
    "    client_id = '6a7cb31c7b4d48bfa37ad4a2fda6b0e4'\n",
    "    client_secret = 'fb1aa602521a4f618c316e9301f79f30'\n",
    "\n",
    "    credentials = oauth2.SpotifyClientCredentials(\n",
    "        client_id = client_id,\n",
    "        client_secret = client_secret)\n",
    "\n",
    "    token = credentials.get_access_token()\n",
    "    spotify = spotipy.Spotify(auth = token)\n",
    "    \n",
    "    search = user_playlist_tracks_full(spotify, user, playlist_id = playlist , market = 'US')\n",
    "    \n",
    "    artist_name = [search[i]['track']['artists'][0]['name'] for i in range(len(search))]\n",
    "    artist_id = [search[i]['track']['artists'][0]['id'] for i in range(len(search))]\n",
    "    track_name = [search[i]['track']['name'] for i in range(len(search))]\n",
    "    track_id = [search[i]['track']['id'] for i in range(len(search))]\n",
    "    release_date = [search[i]['track']['album']['release_date'] for i in range(len(search))]\n",
    "    popularity_metric = [search[i]['track']['popularity'] for i in range(len(search))]\n",
    "    \n",
    "    audio_features = spotify.audio_features(track_id[0:100])\n",
    "    for i in range(0, int(len(search)/100)-1):\n",
    "        audio_features.extend(spotify.audio_features(track_id[100+100*i: 200+100*i]))\n",
    "        \n",
    "    genre = [spotify.artists(artist_id[0:50])['artists'][i]['genres'] for i in range(0, 50)]\n",
    "    for i in range(0, int(len(search)/50)-1):\n",
    "        for g in range(0,50):\n",
    "            genre.append(spotify.artists(artist_id[50+(50*i): 100+(50*i)])['artists'][g]['genres'])\n",
    "        \n",
    "    song_df = pd.DataFrame(audio_features)\n",
    "    song_df['track'] = track_name\n",
    "    song_df['artist'] = artist_name\n",
    "    song_df['release_date'] = release_date\n",
    "    song_df['artist_id'] = artist_id\n",
    "    song_df['track_id'] = track_id\n",
    "    song_df['popularity'] = popularity_metric\n",
    "    song_df['genre'] = genre\n",
    "    \n",
    "    return song_df    \n",
    "\n",
    "def scrape_billboard(ranking_week): #format '2018-01-06'\n",
    "\n",
    "    data_path = os.getcwd() + '/data/billboard_weeks/billboard_{}.pickle'.format(ranking_week)\n",
    "    url = 'https://www.billboard.com/charts/hot-100/{}'.format(ranking_week)\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BS(page, 'lxml')\n",
    "\n",
    "    items = soup.find_all('div', {'class': 'chart-list-item'})\n",
    "    rank = soup.find_all('div', {'class': 'chart-list-item__rank'})\n",
    "    song_title = soup.find_all('div', {'class': 'chart-list-item__title'})\n",
    "    artist_name = soup.find_all('div', {'class': 'chart-list-item__artist'})\n",
    "\n",
    "    headers = ['ranking', 'title', 'artist', 'rank_week']\n",
    "    weekly_rank = [rank[i].string.replace('\\n','').strip() for i in range(len(items))]\n",
    "    title = [song_title[i].text.replace('\\n','').strip() for i in range(len(items))]\n",
    "    artist = [artist_name[i].text.replace('\\n','').strip() for i in range(len(items))]\n",
    "    wk_ranking = [ranking_week] * len(items)\n",
    "\n",
    "    billboard_top = dict(zip(headers, [weekly_rank, title, artist, wk_ranking]))\n",
    "\n",
    "    return pd.DataFrame(billboard_top).to_pickle(data_path)\n",
    "\n",
    "def generate_billboard_weeks(start_date, end_date):\n",
    "    '''\n",
    "    Returns a pickle file for the range of weeks given;\n",
    "    '''\n",
    "    start = datetime.datetime.strptime(start_date, '%m/%d/%y')\n",
    "    assert start.weekday() == 5, 'The start of the week must begin on a Saturday'\n",
    "    end = datetime.datetime.strptime(end_date, '%m/%d/%y')\n",
    "\n",
    "    for week in range(0, ((end-start).days// 7) + 1):\n",
    "        scrape_billboard(datetime.datetime.strftime(start + datetime.timedelta(days = 7 * week), '%Y-%m-%d'))\n",
    "    return None\n",
    "\n",
    "def merge_billboard(start_date, end_date):\n",
    "\n",
    "    start = datetime.datetime.strptime(start_date, '%m/%d/%y')\n",
    "    assert start.weekday() == 5, 'The start of the week must begin on a Saturday'\n",
    "    end = datetime.datetime.strptime(end_date, '%m/%d/%y')\n",
    "    '''\n",
    "    Merges the pickle files in the given date range\n",
    "    start = dt.datetime.strptime(start_date, '%m/%d/%y')\n",
    "    assert start.weekday() == 5, 'The start of the week must begin on a Saturday'\n",
    "    end = dt.datetime.strptime(end_date, '%m/%d/%y')\n",
    "    '''\n",
    "    dfs = []\n",
    "    for week in range(0, ((end-start).days// 7) + 1):\n",
    "        formatted_date = datetime.datetime.strftime(start + datetime.timedelta(days = 7 * week), '%Y-%m-%d')\n",
    "        dfs.append(pd.read_pickle(os.getcwd() + '/data/billboard_weeks/billboard_{}.pickle'.format(formatted_date)))\n",
    "        billboard_df = pd.concat(dfs, axis = 0, ignore_index = True)\n",
    "    return billboard_df\n",
    "\n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold, limit):\n",
    "    \n",
    "    '''\n",
    "    df_1 is the left table to join\n",
    "    df_2 is the right table to join\n",
    "    key1 is the key column of the left table\n",
    "    key2 is the key column of the right table\n",
    "    threshold is how close the matches should be to return a match\n",
    "    limit is the amount of matches will get returned, these are sorted high to low\n",
    "    '''\n",
    "    \n",
    "    s = df_2[key2].tolist()\n",
    "    \n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))\n",
    "    df_1['matches'] = m\n",
    "    \n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:32:36.605829Z",
     "start_time": "2019-10-16T21:32:36.600636Z"
    }
   },
   "outputs": [],
   "source": [
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold, limit):\n",
    "    \n",
    "    '''\n",
    "    df_1 is the left table to join\n",
    "    df_2 is the right table to join\n",
    "    key1 is the key column of the left table\n",
    "    key2 is the key column of the right table\n",
    "    threshold is how close the matches should be to return a match\n",
    "    limit is the amount of matches will get returned, these are sorted high to low\n",
    "    '''\n",
    "    \n",
    "    s = df_2[key2].tolist()\n",
    "    \n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))\n",
    "    df_1['matches'] = m\n",
    "    \n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Audio Features from Spotify Web API via Spotipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T20:25:33.512984Z",
     "start_time": "2019-10-11T20:25:33.413188Z"
    }
   },
   "outputs": [],
   "source": [
    "client_id = '6a7cb31c7b4d48bfa37ad4a2fda6b0e4'\n",
    "client_secret = 'fb1aa602521a4f618c316e9301f79f30'\n",
    "\n",
    "credentials = oauth2.SpotifyClientCredentials(\n",
    "              client_id = client_id,\n",
    "              client_secret = client_secret)\n",
    "\n",
    "token = credentials.get_access_token()\n",
    "spotify = spotipy.Spotify(auth = token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T20:24:23.782992Z",
     "start_time": "2019-10-11T20:24:23.779568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Available playlist to choose from:\n",
    "songs_2018 = '7drSV2jTKxdPXsLHM12s5I'\n",
    "# Main Project 3 Playlist: 10,000 songs across 2018. Not carefully selected\n",
    "albums_2018 = '64EuP1gJFje1HJn0PrZlS8'\n",
    "# Playlist based on albums released in 2018; may not capture singles released\n",
    "singles_2018 = '6qr9d6frpDxgbk8KxpJ1rL'\n",
    "# Playlist that captures songs not in either list \n",
    "may_2018_playlist = '19vrv5El1RKLqkNArxvo6F'\n",
    "# Test playlist for fun; shared playlist\n",
    "study_playlist = '4X7oYDGcLzW9llFdFkDilo'\n",
    "# Additional playlist for fun; personal playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T20:24:27.750866Z",
     "start_time": "2019-10-11T20:24:27.743570Z"
    }
   },
   "outputs": [],
   "source": [
    "column_order = ['track', 'artist','acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "                'speechiness', 'tempo', 'valence', 'genre', 'duration_ms', 'release_date', 'id', 'artist_id', 'track_id', 'popularity', 'analysis_url', 'time_signature', 'track_href',\n",
    "                'type', 'uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T21:33:29.222117Z",
     "start_time": "2019-07-30T21:32:51.423947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions extracts audio features from 10000 song playlist\n",
    "song_df = scrape_spotify('jc98924', songs_2018)\n",
    "\n",
    "# Reorder the columns accordingly \n",
    "song_df = song_df[column_order]\n",
    "\n",
    "# Save to .csv file\n",
    "song_df.to_csv(raw_path + 'song_df_unaltered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T20:39:42.303810Z",
     "start_time": "2019-08-03T20:38:36.541338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions extracts audio features from curated playlist based on albums released + select songs\n",
    "album_df = scrape_spotify('jc98924', albums_2018)\n",
    "\n",
    "# Reorder the columns accordingly \n",
    "album_df = album_df[column_order]\n",
    "\n",
    "album_df.to_csv(raw_path + 'album_df_unaltered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T17:24:47.258046Z",
     "start_time": "2019-07-30T17:24:46.791530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run code to obtain the billboard_df for the specified date range. \n",
    "billboard_df = merge_billboard('01/06/18', '06/29/19')\n",
    "# Save to .csv file\n",
    "billboard_df.to_csv(raw_path + 'billboard_df_unaltered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With genres included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = '6a7cb31c7b4d48bfa37ad4a2fda6b0e4'\n",
    "client_secret = 'fb1aa602521a4f618c316e9301f79f30'\n",
    "\n",
    "credentials = oauth2.SpotifyClientCredentials(\n",
    "    client_id = client_id,\n",
    "    client_secret = client_secret)\n",
    "\n",
    "token = credentials.get_access_token()\n",
    "spotify = spotipy.Spotify(auth = token)\n",
    "\n",
    "search = user_playlist_tracks_full(spotify, 'jc98924', playlist_id = albums_2018 , market = 'US')\n",
    "\n",
    "artist_name = [search[i]['track']['artists'][0]['name'] for i in range(len(search))]\n",
    "artist_id = [search[i]['track']['artists'][0]['id'] for i in range(len(search))]\n",
    "track_name = [search[i]['track']['name'] for i in range(len(search))]\n",
    "track_id = [search[i]['track']['id'] for i in range(len(search))]\n",
    "release_date = [search[i]['track']['album']['release_date'] for i in range(len(search))]\n",
    "popularity_metric = [search[i]['track']['popularity'] for i in range(len(search))]\n",
    "\n",
    "audio_features = spotify.audio_features(track_id[0:100])\n",
    "for i in range(0, int(len(search)/100)-1):\n",
    "    audio_features.extend(spotify.audio_features(track_id[100+100*i: 200+100*i]))\n",
    "\n",
    "song_df = pd.DataFrame(audio_features)\n",
    "song_df['track'] = track_name\n",
    "song_df['artist'] = artist_name\n",
    "song_df['release_date'] = release_date\n",
    "song_df['artist_id'] = artist_id\n",
    "song_df['track_id'] = track_id\n",
    "song_df['popularity'] = popularity_metric\n",
    "\n",
    "# Extremely inefficient line of code, need to find a better method\n",
    "genre = [spotify.artists(artist_id[0:50])['artists'][i]['genres'] for i in range(0, 50)]\n",
    "for i in range(0, int(len(search)/50)-1):\n",
    "    for g in range(0,50):\n",
    "        genre.append(spotify.artists(artist_id[50+(50*i): 100+(50*i)])['artists'][g]['genres'])\n",
    "\n",
    "song_df['genre'] = genre\n",
    "\n",
    "song_df.to_pickle(raw_path + 'song_df_genre.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = '6a7cb31c7b4d48bfa37ad4a2fda6b0e4'\n",
    "client_secret = 'fb1aa602521a4f618c316e9301f79f30'\n",
    "\n",
    "credentials = oauth2.SpotifyClientCredentials(\n",
    "    client_id = client_id,\n",
    "    client_secret = client_secret)\n",
    "\n",
    "token = credentials.get_access_token()\n",
    "spotify = spotipy.Spotify(auth = token)\n",
    "\n",
    "search = user_playlist_tracks_full(spotify, 'jc98924', playlist_id = albums_2018 , market = 'US')\n",
    "\n",
    "artist_name = [search[i]['track']['artists'][0]['name'] for i in range(len(search))]\n",
    "artist_id = [search[i]['track']['artists'][0]['id'] for i in range(len(search))]\n",
    "track_name = [search[i]['track']['name'] for i in range(len(search))]\n",
    "track_id = [search[i]['track']['id'] for i in range(len(search))]\n",
    "release_date = [search[i]['track']['album']['release_date'] for i in range(len(search))]\n",
    "popularity_metric = [search[i]['track']['popularity'] for i in range(len(search))]\n",
    "\n",
    "audio_features = spotify.audio_features(track_id[0:100])\n",
    "for i in range(0, int(len(search)/100)-1):\n",
    "    audio_features.extend(spotify.audio_features(track_id[100+100*i: 200+100*i]))\n",
    "\n",
    "album_df = pd.DataFrame(audio_features)\n",
    "album_df['track'] = track_name\n",
    "album_df['artist'] = artist_name\n",
    "album_df['release_date'] = release_date\n",
    "album_df['artist_id'] = artist_id\n",
    "album_df['track_id'] = track_id\n",
    "album_df['popularity'] = popularity_metric\n",
    "\n",
    "# Extremely inefficient line of code, need to find a better method\n",
    "genre = [spotify.artists(artist_id[0:50])['artists'][i]['genres'] for i in range(0, 50)]\n",
    "for i in range(0, int(len(search)/50)-1):\n",
    "    for g in range(0,50):\n",
    "        genre.append(spotify.artists(artist_id[50+(50*i): 100+(50*i)])['artists'][g]['genres'])\n",
    "        \n",
    "album_df['genre'] = genre\n",
    "\n",
    "album_df.to_pickle(raw_path + 'album_df_genre.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Cleaning and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T01:01:02.932273Z",
     "start_time": "2019-10-12T01:01:02.858282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of song_df is 9621\n",
      "The length of billboard_df is 955\n"
     ]
    }
   ],
   "source": [
    "# For using the playlist based on 10,000 songs\n",
    "billboard_df = pd.read_csv(raw_path + 'billboard_df_unaltered.csv')\n",
    "\n",
    "song_df = pd.read_pickle(raw_path + 'song_df_with_genres')\n",
    "\n",
    "song_df['index'] = song_df['track'] + ' ' + song_df['artist']\n",
    "billboard_df['index'] = billboard_df['title'] + ' ' + billboard_df['artist']\n",
    "\n",
    "billboard_df.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "song_df.drop_duplicates(subset = ['track','artist'], keep = 'first', inplace = True)\n",
    "print('The length of {} is {}'.format('song_df',len(song_df)))\n",
    "print('The length of {} is {}'.format('billboard_df',len(billboard_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T01:00:51.451396Z",
     "start_time": "2019-10-12T01:00:51.386811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of album_df is 5393\n",
      "The length of billboard_df is 955\n"
     ]
    }
   ],
   "source": [
    "# For the playlist based on 5400 songs\n",
    "billboard_df = pd.read_csv(raw_path + 'billboard_df_unaltered.csv')\n",
    "\n",
    "album_df = pd.read_pickle(raw_path + 'album_df_with_genres.pickle')\n",
    "\n",
    "billboard_df['index'] = billboard_df['title'] + ' ' + billboard_df['artist']\n",
    "album_df['index'] = album_df['track'] + ' ' + album_df['artist']\n",
    "billboard_df.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "\n",
    "album_df.drop_duplicates(subset = 'index', keep = 'first', inplace = True)\n",
    "print('The length of {} is {}'.format('album_df',len(album_df)))\n",
    "print('The length of {} is {}'.format('billboard_df',len(billboard_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FuzzyMerging with Billboard Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### album_df: threshold 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T21:45:39.861532Z",
     "start_time": "2019-08-03T21:38:34.126328Z"
    }
   },
   "outputs": [],
   "source": [
    "album_88 = fuzzy_merge(album_df, billboard_df, 'index', 'index', threshold = 88, limit = 1)\n",
    "album_88.to_csv(fuzzy_path + 'album_88_genre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T19:06:30.573713Z",
     "start_time": "2019-08-06T19:06:30.503388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album_88 = pd.read_csv(fuzzy_path + 'album_88_genre.csv')\n",
    "len(album_88[~album_88['matches'].isnull()])\n",
    "# Dataframe is 5393 rows long, has 414 match entries, 7.67%; Most correct except Hunch Jack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### album_df: threshold 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T22:40:41.600495Z",
     "start_time": "2019-07-30T22:33:13.558129Z"
    }
   },
   "outputs": [],
   "source": [
    "album_merge_92 = fuzzy_merge(album_df, billboard_df, 'index', 'index', threshold = 92, limit = 1)\n",
    "album_merge_92.to_csv(fuzzy_path + 'album_merge_92.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T22:45:44.362885Z",
     "start_time": "2019-07-30T22:45:44.291189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album_merge_92 = pd.read_csv(fuzzy_path + 'album_merge_92.csv')\n",
    "len(album_merge_92[~album_merge_92['matches'].isnull()])\n",
    "# Album_df length is 5393, 298 matched entries, 5.52% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### song_df: threshold 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df_86 = fuzzy_merge(song_df, billboard_df, 'index', 'index', threshold = 86, limit = 1)\n",
    "merge_df_86.to_csv(fuzzy_path + 'fuzzy_merge_86.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T22:42:53.631194Z",
     "start_time": "2019-07-30T22:42:53.515290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7551"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_86 = pd.read_csv(fuzzy_path + 'fuzzy_merge_86.csv')\n",
    "len(merge_86[~merge_86['matches'].isnull()])\n",
    "# Do not use model, too many false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### song_df: threshold 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df_88 = fuzzy_merge(song_df, billboard_df, 'index', 'index', threshold = 86, limit = 1)\n",
    "merge_df_88.to_csv(fuzzy_path + 'fuzzy_merge_88.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T01:04:13.911557Z",
     "start_time": "2019-10-12T01:04:13.810595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_88 = pd.read_csv(fuzzy_path + 'fuzzy_merge_88.csv')\n",
    "len(merge_88[~merge_88['matches'].isnull()])\n",
    "# Do not use model, too many false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### song_df: threshold 90 (Best Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T03:38:15.691516Z",
     "start_time": "2019-08-03T03:26:18.404192Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merge_90 = fuzzy_merge(song_df, billboard_df, 'index', 'index', threshold = 90, limit =1)\n",
    "merge_90.to_csv(fuzzy_path + 'merge_90_with_genre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T01:04:06.994232Z",
     "start_time": "2019-10-12T01:04:06.870214Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_90 = pd.read_csv(fuzzy_path + 'merge_90_with_genre.csv')\n",
    "len(merge_90[~merge_90['matches'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### song_df: threshold 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T18:05:02.091594Z",
     "start_time": "2019-07-30T17:48:57.709672Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merge_df_92 = fuzzy_merge(song_df, billboard_df, 'index', 'index', threshold = 92, limit = 1)\n",
    "merge_df_92.to_csv(fuzzy_path + 'fuzzy_merge_92.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T01:04:58.199832Z",
     "start_time": "2019-10-12T01:04:58.099516Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_92 = pd.read_csv(fuzzy_path + 'fuzzy_merge_92.csv')\n",
    "len(merge_92[~merge_92['matches'].isnull()])\n",
    "# Original DataFrame, 92 threshold, length of 9621, 409 positives, 4.25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### song_df: threshold 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merge_df_94 = fuzzy_merge(song_df, billboard_df, 'index', 'index', threshold = 94, limit = 1)\n",
    "merge_df_94.to_csv(fuzzy_path + 'fuzzy_merge_94.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T01:05:42.762235Z",
     "start_time": "2019-10-12T01:05:42.661188Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_94 = pd.read_csv(fuzzy_path + 'fuzzy_merge_94.csv')\n",
    "len(merge_94[~merge_94['matches'].isnull()])\n",
    "# Original DataFrame, 94 threshold, length of 9621, 405 positives, 4.20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create positive class labels and further cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:39:14.326820Z",
     "start_time": "2019-10-16T21:39:14.259423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Chose to go the path of the albums (5,400 songs vs 10,000)\n",
    "album_88 = pd.read_csv(fuzzy_path + 'album_88_genre.csv')\n",
    "df = album_88.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_analysis_df(df, attribute_scale):\n",
    "    df['pop'] = [1 if 'pop' in x else 0 for x in df['genre']]\n",
    "    df['rap'] = [1 if 'rap' in x else 0 for x in df['genre']]\n",
    "    df['hip-hop'] = [1 if 'hip' in x else 0 for x in df['genre']]\n",
    "    df['country'] = [1 if 'country' in x else 0 for x in df['genre']]\n",
    "    df['electronic'] = [1 if 'edm' in x else 0 for x in df['genre']]\n",
    "    df['rock'] = [1 if 'rock' in x else 0 for x in df['genre']]\n",
    "    df['indie'] = [1 if 'indie' in x else 0 for x in df['genre']]\n",
    "    df['house'] = [1 if 'house' in x else 0 for x in df['genre']]\n",
    "    df['metal'] = [1 if 'metal' in x else 0 for x in df['genre']]\n",
    "    df['jazz'] = [1 if 'jazz' in x else 0 for x in df['genre']]\n",
    "    df['soul'] = [1 if 'soul' in x else 0 for x in df['genre']]\n",
    "    df['reggaeton'] = [1 if 'reggaeton' in x else 0 for x in df['genre']]\n",
    "\n",
    "    df['sum'] = df['pop'] + df['rap'] + df['hip-hop'] \\\n",
    "    + df['country'] + df['electronic'] + df['rock'] + df['indie'] \\\n",
    "    + df['house'] + df['metal'] + df['jazz'] + df['soul'] + df['reggaeton']\\\n",
    "\n",
    "    df['other'] = [1 if x == 0 else 0 for x in df['sum']]\n",
    "    \n",
    "    df['matches'].fillna(0, inplace = True)\n",
    "    df['success'] = [0 if x == 0 else 1 for x in df['matches']]\n",
    "    \n",
    "    feature_selection = ['success','acousticness', 'danceability', 'energy', \n",
    "                         'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "                         'speechiness', 'tempo', 'valence', 'duration_ms', 'release_date',\n",
    "                         'popularity','artist','track', 'pop', 'rap', 'hip-hop', 'country',\n",
    "                         'electronic', 'rock', 'indie', 'house', 'metal', 'jazz', 'soul', \n",
    "                         'reggaeton', 'other']\n",
    "    \n",
    "    spotify_df = df[feature_selection].copy()\n",
    "    spotify_df['index'] = spotify_df['artist'] + ': ' + spotify_df['track']\n",
    "    spotify_df.set_index('index', inplace = True)\n",
    "    spotify_df['minutes'] = spotify_df['duration_ms']/60000\n",
    "    spotify_df['release_date'] = pd.to_datetime(spotify_df['release_date'])\n",
    "    spotify_df.drop(['artist', 'track', 'duration_ms'], axis = 1, inplace = True)\n",
    "    \n",
    "    spotify_df['acousticness'] = spotify_df['acousticness'] * attribute_scale\n",
    "    spotify_df['danceability'] = spotify_df['danceability'] * attribute_scale\n",
    "    spotify_df['energy'] = spotify_df['energy'] * attribute_scale\n",
    "    spotify_df['instrumentalness'] = spotify_df['instrumentalness'] * attribute_scale\n",
    "    spotify_df['liveness'] = spotify_df['liveness'] * attribute_scale\n",
    "    spotify_df['speechiness'] = spotify_df['speechiness'] * attribute_scale\n",
    "    spotify_df['valence'] = spotify_df['valence'] * attribute_scale\n",
    "    \n",
    "    return spotify_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_sp_df = clean_analysis_df(df, 100)\n",
    "# Manually change specific predictors that were classed as positive \n",
    "album_sp_df['success'].iloc[5362] = 0\n",
    "album_sp_df['success'].iloc[5367:5373] = 0\n",
    "\n",
    "album_sp_df.to_pickle(model_path + 'spotify_album_analysis.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = clean_analysis_df(pd.read_csv(fuzzy_path + 'merge_90_with_genre.csv'), 100)\n",
    "\n",
    "# Export to pickle file; Analysis of model located in project_3_spotify_analysis\n",
    "spotify_df.to_pickle(model_path + 'spotify_analysis.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for Tableau (with Artist/Track names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:39:33.921734Z",
     "start_time": "2019-10-16T21:39:33.898022Z"
    }
   },
   "outputs": [],
   "source": [
    "def tableau_clean_df(df, attribute_scale):\n",
    "    df['pop'] = [1 if 'pop' in x else 0 for x in df['genre']]\n",
    "    df['rap'] = [1 if 'rap' in x else 0 for x in df['genre']]\n",
    "    df['hip-hop'] = [1 if 'hip' in x else 0 for x in df['genre']]\n",
    "    df['country'] = [1 if 'country' in x else 0 for x in df['genre']]\n",
    "    df['electronic'] = [1 if 'edm' in x else 0 for x in df['genre']]\n",
    "    df['rock'] = [1 if 'rock' in x else 0 for x in df['genre']]\n",
    "    df['indie'] = [1 if 'indie' in x else 0 for x in df['genre']]\n",
    "    df['house'] = [1 if 'house' in x else 0 for x in df['genre']]\n",
    "    df['metal'] = [1 if 'metal' in x else 0 for x in df['genre']]\n",
    "    df['jazz'] = [1 if 'jazz' in x else 0 for x in df['genre']]\n",
    "    df['soul'] = [1 if 'soul' in x else 0 for x in df['genre']]\n",
    "    df['reggaeton'] = [1 if 'reggaeton' in x else 0 for x in df['genre']]\n",
    "\n",
    "    df['sum'] = df['pop'] + df['rap'] + df['hip-hop'] \\\n",
    "    + df['country'] + df['electronic'] + df['rock'] + df['indie'] \\\n",
    "    + df['house'] + df['metal'] + df['jazz'] + df['soul'] + df['reggaeton']\\\n",
    "\n",
    "    df['other'] = [1 if x == 0 else 0 for x in df['sum']]\n",
    "    \n",
    "    df['matches'].fillna(0, inplace = True)\n",
    "    df['success'] = [0 if x == 0 else 1 for x in df['matches']]\n",
    "    \n",
    "    feature_selection = ['success','acousticness', 'danceability', 'energy', \n",
    "                         'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "                         'speechiness', 'tempo', 'valence', 'duration_ms', 'release_date',\n",
    "                         'popularity','artist','track', 'pop', 'rap', 'hip-hop', 'country',\n",
    "                         'electronic', 'rock', 'indie', 'house', 'metal', 'jazz', 'soul', \n",
    "                         'reggaeton', 'other']\n",
    "    \n",
    "    spotify_df = df[feature_selection].copy()\n",
    "    spotify_df['index'] = spotify_df['artist'] + ': ' + spotify_df['track']\n",
    "    spotify_df.set_index('index', inplace = True)\n",
    "    spotify_df['minutes'] = spotify_df['duration_ms']/60000\n",
    "    spotify_df['release_date'] = pd.to_datetime(spotify_df['release_date'])\n",
    "    spotify_df.drop(['duration_ms'], axis = 1, inplace = True)\n",
    "    \n",
    "    spotify_df['acousticness'] = spotify_df['acousticness'] * attribute_scale\n",
    "    spotify_df['danceability'] = spotify_df['danceability'] * attribute_scale\n",
    "    spotify_df['energy'] = spotify_df['energy'] * attribute_scale\n",
    "    spotify_df['instrumentalness'] = spotify_df['instrumentalness'] * attribute_scale\n",
    "    spotify_df['liveness'] = spotify_df['liveness'] * attribute_scale\n",
    "    spotify_df['speechiness'] = spotify_df['speechiness'] * attribute_scale\n",
    "    spotify_df['valence'] = spotify_df['valence'] * attribute_scale\n",
    "    \n",
    "    return spotify_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:39:37.064793Z",
     "start_time": "2019-10-16T21:39:36.905727Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jc98924/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "tableau_df = tableau_clean_df(df, 100)\n",
    "tableau_df['success'].iloc[5362] = 0\n",
    "tableau_df['success'].iloc[5367:5373] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:40:13.832755Z",
     "start_time": "2019-10-16T21:40:13.827820Z"
    }
   },
   "outputs": [],
   "source": [
    "df = tableau_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:40:18.395111Z",
     "start_time": "2019-10-16T21:40:18.355656Z"
    }
   },
   "outputs": [],
   "source": [
    "df['hip_merge'] = df['rap'] + df['hip-hop'] + df['reggaeton']\n",
    "df['rock_merge'] = df['rock'] + df['metal']\n",
    "df['edm_merge'] = df['electronic'] + df['house']\n",
    "df['jazz_merge'] = df['jazz'] + df['soul']\n",
    "\n",
    "df['rap/hip-hop'] = [1 if x >= 1 else 0 for x in df['hip_merge']]\n",
    "df['ROCK'] = [1 if x >= 1 else 0 for x in df['rock_merge']]\n",
    "df['edm'] = [1 if x >= 1 else 0 for x in df['edm_merge']]\n",
    "df['JAZZ'] = [1 if x >= 1 else 0 for x in df['jazz_merge']]\n",
    "\n",
    "conditions = [\n",
    "    (df['pop'] == 1) & (df['rap/hip-hop'] == 1),\n",
    "    (df['pop'] == 1) & (df['rap/hip-hop'] == 0)\n",
    "]\n",
    "choices = [0, 1]\n",
    "df['POP'] = np.select(conditions, choices, default = 0)\n",
    "\n",
    "df.drop(['pop','rap','hip-hop','electronic','rock','house','metal','jazz','soul','reggaeton','rock_merge','edm_merge','jazz_merge','hip_merge'],\n",
    "        axis = 1, inplace = True)\n",
    "df.rename(columns = lambda x: x.lower(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:40:22.775636Z",
     "start_time": "2019-10-16T21:40:22.765124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2846\n",
       "1    2547\n",
       "Name: pop, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pop'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T21:40:40.946604Z",
     "start_time": "2019-10-16T21:40:40.938231Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle(model_path + 'album_df_additional_genre_cleaning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T21:33:54.792328Z",
     "start_time": "2019-08-06T21:33:54.785131Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle('tabl_genre.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if df['pop'] == 1 & df['rap/hip-hop'] == 1, df['pop'] = 0\n",
    "#else if df['pop'] == 1, df['POP'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T18:35:31.940553Z",
     "start_time": "2019-08-06T18:35:31.930600Z"
    }
   },
   "outputs": [],
   "source": [
    "df['rap/hip-hop'].value_counts()\n",
    "df['rap/hip-hop'] = [1 if x >= 1 else 0 for x in df['hip_sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T18:33:08.716836Z",
     "start_time": "2019-08-06T18:33:08.708207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5031\n",
       "1     362\n",
       "Name: other, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    df['other'] = [1 if x == 0 else 0 for x in df['sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T18:28:18.154531Z",
     "start_time": "2019-08-06T18:28:18.151206Z"
    }
   },
   "outputs": [],
   "source": [
    "pop_mask = ((tableau_df['pop'] == 1))\n",
    "rap_mask = ((tableau_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T18:29:16.976784Z",
     "start_time": "2019-08-06T18:29:14.701640Z"
    }
   },
   "outputs": [],
   "source": [
    "tableau_df[pop_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T03:22:04.596404Z",
     "start_time": "2019-08-06T03:22:04.392571Z"
    }
   },
   "outputs": [],
   "source": [
    "tableau_df.to_csv('tableau_df_artist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
